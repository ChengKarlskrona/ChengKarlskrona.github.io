<!doctype html>



  


<html class="theme-next mist use-motion">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>



<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />












  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />




  
  
  
  

  
    
    
  

  

  

  

  

  
    
    
    <link href="//fonts.googleapis.com/css?family=Lato:300,300italic,400,400italic,700,700italic&subset=latin,latin-ext" rel="stylesheet" type="text/css">
  






<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.4.0" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.0" rel="stylesheet" type="text/css" />


  <meta name="keywords" content="Python,BeautifulSoup,requests,javascript," />








  <link rel="shortcut icon" type="image/x-icon" href="/favicon.ico?v=5.1.0" />






<meta name="description" content="Background58 website is a secondhand e-shop, now we plan to scrapy the second-hand mobile website’s list and each list’s detail, we can see on the following picture:">
<meta name="keywords" content="Python,BeautifulSoup,requests,javascript">
<meta property="og:type" content="article">
<meta property="og:title" content="Practice3: Scrapying 58 WebSite List And Detail">
<meta property="og:url" content="http://clovel.cn/2017/04/01/Practice-3_-Scrapying-58-Web-Site-List-And-Detail/index.html">
<meta property="og:site_name" content="Code_Cheng Site">
<meta property="og:description" content="Background58 website is a secondhand e-shop, now we plan to scrapy the second-hand mobile website’s list and each list’s detail, we can see on the following picture:">
<meta property="og:locale" content="en">
<meta property="og:image" content="http://clovel.cn/images/58_2.png">
<meta property="og:image" content="http://clovel.cn/images/58_6.png">
<meta property="og:image" content="http://clovel.cn/images/58_4.png">
<meta property="og:image" content="http://clovel.cn/images/58_7.png">
<meta property="og:image" content="http://clovel.cn/images/58_5.png">
<meta property="og:updated_time" content="2017-04-02T09:43:40.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Practice3: Scrapying 58 WebSite List And Detail">
<meta name="twitter:description" content="Background58 website is a secondhand e-shop, now we plan to scrapy the second-hand mobile website’s list and each list’s detail, we can see on the following picture:">
<meta name="twitter:image" content="http://clovel.cn/images/58_2.png">



<script type="text/javascript" id="hexo.configuration">
  var NexT = window.NexT || {};
  var CONFIG = {
    scheme: 'Mist',
    sidebar: {"position":"left","display":"post","offset":12,"offset_float":0,"b2t":false,"scrollpercent":false},
    fancybox: true,
    motion: true,
    duoshuo: {
      userId: 0,
      author: 'Author'
    }
  };
</script>




  <link rel="canonical" href="http://clovel.cn/2017/04/01/Practice-3_-Scrapying-58-Web-Site-List-And-Detail/"/>

  <title> Practice3: Scrapying 58 WebSite List And Detail | Code_Cheng Site </title>
</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  










  
  
    
  

  <div class="container one-collumn sidebar-position-left page-post-detail ">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-meta ">
  

  <div class="custom-logo-site-title">
    <a href="/"  class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <span class="site-title">Code_Cheng Site</span>
      <span class="logo-line-after"><i></i></span>
    </a>
  </div>
  <p class="site-subtitle">python | html5 | javascript | database | Everything I Want</p>
</div>

<div class="site-nav-toggle">
  <button>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
    <span class="btn-bar"></span>
  </button>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-categories">
          <a href="/categories" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-th"></i> <br />
            
            Categories
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-commonweal">
          <a href="/404.html" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-heartbeat"></i> <br />
            
            Commonweal 404
          </a>
        </li>
      

      

      <!-- 自定义High一下的功能 -->
      <li class="menu-item"> <a title="把这个链接拖到你的工具栏中,任何网页都可以High" href='javascript:(
    /*
     * Copyright (C) 2016 Never_yu (Neveryu.github.io) <React.dong.yu@gmail.com>
     * Sina Weibo (http://weibo.com/Neveryu)
     *
     * Licensed under the Apache License, Version 2.0 (the "License");
     * you may not use this file except in compliance with the License.
     * You may obtain a copy of the License at
     *
     *      http://www.apache.org/licenses/LICENSE-2.0
     *
     * Unless required by applicable law or agreed to in writing, software
     * distributed under the License is distributed on an "AS IS" BASIS,
     * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
     * See the License for the specific language governing permissions and
     * limitations under the License.
     */
    function go() {


    var songs = [
                "http://bdyun.65dj.com:8090/2015/06/28/84791C997D8C55023DAD0D5690E48C28/%D1%A6%D6%AE%C7%AB%20-%20%D1%DD%D4%B1.mp3",
                "http://7xoiki.com1.z0.glb.clouddn.com/Music-sunburst.mp3",
                ""
    ];

    
    function c() {
        var e = document.createElement("link");
        e.setAttribute("type", "text/css");
        e.setAttribute("rel", "stylesheet");
        e.setAttribute("href", f);
        e.setAttribute("class", l);
        document.body.appendChild(e)
    }
 
    function h() {
        var e = document.getElementsByClassName(l);
        for (var t = 0; t < e.length; t++) {
            document.body.removeChild(e[t])
        }
    }
 
    function p() {
        var e = document.createElement("div");
        e.setAttribute("class", a);
        document.body.appendChild(e);
        setTimeout(function() {
            document.body.removeChild(e)
        }, 100)
    }
 
    function d(e) {
        return {
            height : e.offsetHeight,
            width : e.offsetWidth
        }
    }
 
    function v(i) {
        var s = d(i);
        return s.height > e && s.height < n && s.width > t && s.width < r
    }
 
    function m(e) {
        var t = e;
        var n = 0;
        while (!!t) {
            n += t.offsetTop;
            t = t.offsetParent
        }
        return n
    }
 
    function g() {
        var e = document.documentElement;
        if (!!window.innerWidth) {
            return window.innerHeight
        } else if (e && !isNaN(e.clientHeight)) {
            return e.clientHeight
        }
        return 0
    }
 
    function y() {
        if (window.pageYOffset) {
            return window.pageYOffset
        }
        return Math.max(document.documentElement.scrollTop, document.body.scrollTop)
    }
 
    function E(e) {
        var t = m(e);
        return t >= w && t <= b + w
    }

    function S() {
        var e = document.getElementById("audio_element_id");
        if(e != null){
            var index = parseInt(e.getAttribute("curSongIndex"));
            if(index > songs.length - 2) {
                index = 0;
            } else {
                index++;
            }
            e.setAttribute("curSongIndex", index);
            N();
        }

        e.src = i;
        e.play()
    }
 
    function x(e) {
        e.className += " " + s + " " + o
    }
 
    function T(e) {
        e.className += " " + s + " " + u[Math.floor(Math.random() * u.length)]
    }
 
    function N() {
        var e = document.getElementsByClassName(s);
        var t = new RegExp("\\b" + s + "\\b");
        for (var n = 0; n < e.length; ) {
            e[n].className = e[n].className.replace(t, "")
        }
    }

    function initAudioEle() {
        var e = document.getElementById("audio_element_id");
        if(e === null){
            e = document.createElement("audio");
            e.setAttribute("class", l);
            e.setAttribute("curSongIndex", 0);
            e.id = "audio_element_id";
            e.loop = false;
            e.bgcolor = 0;
            e.addEventListener("canplay", function() {
            setTimeout(function() {
                x(k)
            }, 500);
            setTimeout(function() {
                N();
                p();
                for (var e = 0; e < O.length; e++) {
                    T(O[e])
                }
            }, 15500)
        }, true);
        e.addEventListener("ended", function() {
            N();
            h();
            go();
        }, true);
        e.innerHTML = " <p>If you are reading this, it is because your browser does not support the audio element. We recommend that you get a new browser.</p> <p>";
        document.body.appendChild(e);
        }
    }
    
    initAudioEle();
    var e = 30;
    var t = 30;
    var n = 350;
    var r = 350;

    var curSongIndex = parseInt(document.getElementById("audio_element_id").getAttribute("curSongIndex"));
    var i = songs[curSongIndex];
    
    var s = "mw-harlem_shake_me";
    var o = "im_first";
    var u = ["im_drunk", "im_baked", "im_trippin", "im_blown"];
    var a = "mw-strobe_light";

    /* harlem-shake-style.css，替换成你的位置，也可以直接使用：//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css */
    var f = "//s3.amazonaws.com/moovweb-marketing/playground/harlem-shake-style.css";
    
    var l = "mw_added_css";
    var b = g();
    var w = y();
    var C = document.getElementsByTagName("*");
    var k = null;
    for (var L = 0; L < C.length; L++) {
        var A = C[L];
        if (v(A)) {
            if (E(A)) {
                k = A;
                break
            }
        }
    }
    if (A === null) {
        console.warn("Could not find a node of the right size. Please try a different page.");
        return
    }
    c();
    S();
    var O = [];
    for (var L = 0; L < C.length; L++) {
        var A = C[L];
        if (v(A)) {
            O.push(A)
        }
    }
    })()'><i class="menu-item-icon fa fa-music fa-fw"></i>High一下</a> </li>
      <!-- end High一下 -->
    </ul>
  

  
</nav>

 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  
  

  
  
  

  <article class="post post-type-normal " itemscope itemtype="http://schema.org/Article">

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">
            
            
              
                Practice3: Scrapying 58 WebSite List And Detail
              
            
          </h1>
        

        <div class="post-meta">
          <span class="post-time">
            <span class="post-meta-item-icon">
              <i class="fa fa-calendar-o"></i>
            </span>
            <span class="post-meta-item-text">Posted on</span>
            <time itemprop="dateCreated" datetime="2017-04-01T21:59:24+02:00" content="2017-04-01">
              2017-04-01
            </time>
          </span>

          
            <span class="post-category" >
              &nbsp; | &nbsp;
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">In</span>
              
                <span itemprop="about" itemscope itemtype="https://schema.org/Thing">
                  <a href="/categories/python/" itemprop="url" rel="index">
                    <span itemprop="name">python</span>
                  </a>
                </span>

                
                

              
            </span>
          

          
            
              <span class="post-comments-count">
                &nbsp; | &nbsp;
                <a href="/2017/04/01/Practice-3_-Scrapying-58-Web-Site-List-And-Detail/#comments" itemprop="discussionUrl">
                  <span class="post-comments-count ds-thread-count" data-thread-key="2017/04/01/Practice-3_-Scrapying-58-Web-Site-List-And-Detail/" itemprop="commentsCount"></span>
                </a>
              </span>
            
          

          

          
          

          
        </div>
      </header>
    


    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Background"><a href="#Background" class="headerlink" title="Background"></a>Background</h1><p>58 website is a secondhand e-shop, now we plan to scrapy the second-hand mobile website’s list and each list’s detail, we can see on the following picture:<br><img src="/images/58_2.png" class="[image1]"><a id="more"></a><br>On the first picture, we do not need scrapying the businesses’ item, we only need scrapying the personal sellers, like the 58 users and zhuanzhuan users.</p>
<h1 id="Scrapying-The-List"><a href="#Scrapying-The-List" class="headerlink" title="Scrapying The List"></a>Scrapying The List</h1><p>Now we start to crawling this page’s information, we need each item’s link:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://bj.58.com/shouji/'</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_list</span><span class="params">(url,data=None)</span>:</span></span><br><span class="line"></span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(resp.text,<span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">    links = soup.select(<span class="string">'tbody &gt; tr &gt; td.t &gt; a.t'</span>)</span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">        link = link.get(<span class="string">'href'</span>).split(<span class="string">'?'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> link[<span class="number">0</span>:<span class="number">26</span>] != <span class="string">'http://jump.zhineng.58.com'</span>:</span><br><span class="line">            print(link)</span><br><span class="line">get_list(url)</span><br></pre></td></tr></table></figure></p>
<p>From the following picture, we can see each businesses item’s url is <code>http://jump.zhineng.58.com...</code>, and the personal 58 seller’s url is like <code>http://bj.58.com/shouji/29540060394298x.shtml</code>, and zhuanzhuan user’s url is <code>http://zhuanzhuan.58.com/detail/848179153081401353z.shtml</code>, so we can use a <code>if...else</code> loop, to remove all businesses item(code line 13).<br><img src="/images/58_6.png" class="[image1]"><br>And the result of this code is :<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">&gt;&gt;&gt; </span>python3 <span class="number">58</span>_list.py</span><br><span class="line">http://bj<span class="number">.58</span>.com/shouji/<span class="number">29540060394298</span>x.shtml</span><br><span class="line">http://bj<span class="number">.58</span>.com/shouji/<span class="number">29453529335367</span>x.shtml</span><br><span class="line">http://bj<span class="number">.58</span>.com/shouji/<span class="number">29298561814583</span>x.shtml</span><br><span class="line">http://bj<span class="number">.58</span>.com/shouji/<span class="number">29517862699182</span>x.shtml</span><br><span class="line">http://bj<span class="number">.58</span>.com/shouji/<span class="number">29558478463567</span>x.shtml</span><br><span class="line">http://zhuanzhuan<span class="number">.58</span>.com/detail/<span class="number">848174528564281352</span>z.shtml</span><br><span class="line">http://zhuanzhuan<span class="number">.58</span>.com/detail/<span class="number">848140382951653387</span>z.shtml</span><br><span class="line">http://zhuanzhuan<span class="number">.58</span>.com/detail/<span class="number">848179153081401353</span>z.shtml</span><br><span class="line">http://zhuanzhuan<span class="number">.58</span>.com/detail/<span class="number">848152696245026824</span>z.shtml</span><br><span class="line">http://zhuanzhuan<span class="number">.58</span>.com/detail/<span class="number">848128647623032840</span>z.shtml</span><br><span class="line">http://zhuanzhuan<span class="number">.58</span>.com/detail/<span class="number">848132162044280840</span>z.shtml</span><br><span class="line">http://zhuanzhuan<span class="number">.58</span>.com/detail/<span class="number">848114003988267021</span>z.shtml</span><br><span class="line">http://zhuanzhuan<span class="number">.58</span>.com/detail/<span class="number">848111912665710605</span>z.shtml</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>
<h1 id="Scrapying-Detail"><a href="#Scrapying-Detail" class="headerlink" title="Scrapying Detail"></a>Scrapying Detail</h1><h2 id="58-Users-Link"><a href="#58-Users-Link" class="headerlink" title="58 Users Link"></a>58 Users Link</h2><p>From the lsit result, we can see the first five is 58 users link, and it will link to this page:<br><img src="/images/58_4.png" class="[image1]"><br>we need scrapy the title,class,view counts,price,area and the publish time, and in this part, view counts is a problem, because we can not get any information.<br>So, we can try to do this:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><span class="line">From bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line">url = <span class="string">'http://bj.58.com/shouji/29448470616899x.shtml'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_review</span><span class="params">(url)</span>:</span></span><br><span class="line">    part_link = url.split(<span class="string">'/'</span>)[<span class="number">-1</span>].strip(<span class="string">'x.shtml'</span>)</span><br><span class="line">    url = <span class="string">'http://jst1.58.com/counter?infoid=&#123;&#125;'</span>.format(str(part_link))</span><br><span class="line">    <span class="comment"># print(url)</span></span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span>,</span><br><span class="line">        <span class="string">'Cookie'</span>:<span class="string">'id58=Ch8BCFjaxDmGEQfEAxATAg==; 58home=bj; als=0; commonTopbar_myfeet_tooltip=end; city=bj; myfeet_tooltip=end; bj58_id58s="WlB6dVpRaTAtTXZ1MTUxNg=="; sessionid=3f9c77fd-4820-45b2-9ec1-168efe3791b2; es_ab=1; 58tj_uuid=aff6d5b1-071f-4599-a863-3583cc4e2c14; new_uv=6; bj58_new_session=1; bj58_init_refer="http://bj.58.com/shouji/"; bj58_new_uv=4'</span>,</span><br><span class="line">        <span class="string">'Accept'</span>:<span class="string">'*/*'</span>,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>:<span class="string">'gzip, deflate, sdch'</span>,</span><br><span class="line">        <span class="string">'Accept-Language'</span>:<span class="string">'zh-CN,zh;q=0.8'</span>,</span><br><span class="line">        <span class="string">'Connection'</span>:<span class="string">'keep-alive'</span>,</span><br><span class="line">        <span class="string">'Host'</span>:<span class="string">'jst1.58.com'</span>,</span><br><span class="line">        <span class="string">'Referer'</span>:<span class="string">'http://bj.58.com/shouji/&#123;&#125;x.shtml'</span>.format(str(part_link))</span><br><span class="line">    &#125;</span><br><span class="line">    resp = requests.get(url,headers=headers)</span><br><span class="line">    <span class="comment"># print(resp.status_code)</span></span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="keyword">return</span> resp.text.split(<span class="string">'='</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_detail_58</span><span class="params">(url,data=None)</span>:</span></span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">        soup = BeautifulSoup(resp.text,<span class="string">'lxml'</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            area_detail = <span class="string">''</span></span><br><span class="line">            are a = soup.select(<span class="string">'ul.suUl &gt; li:nth-of-type(3) &gt; div.su_con &gt; span.c_25d'</span>)[<span class="number">0</span>]</span><br><span class="line">            area = list(area.stripped_strings)</span><br><span class="line">            area = area_detail.join(area)</span><br><span class="line"></span><br><span class="line">            data = &#123;</span><br><span class="line">                <span class="string">'title'</span>:soup.select(<span class="string">'div.per_ad_left &gt; div.col_sub.mainTitle &gt; h1'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'categorie'</span>:soup.select(<span class="string">'div.breadCrumb.f12 &gt; span:nth-of-type(3) &gt; a'</span>)[<span class="number">0</span>].text.replace(<span class="string">'\r\n'</span>,<span class="string">''</span>).strip(),</span><br><span class="line">                <span class="string">'price'</span>:soup.select(<span class="string">'div.su_con &gt; span.price.c_f50'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'area'</span>:area,</span><br><span class="line">                <span class="string">'time'</span>:soup.select(<span class="string">'ul.mtit_con_left.fl &gt; li.time'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'review'</span>:get_review(url)</span><br><span class="line">            &#125;</span><br><span class="line">            print(<span class="string">'Title: '</span>+data[<span class="string">'title'</span>]+<span class="string">'\n'</span>+<span class="string">'Time: '</span>+ data[<span class="string">'time'</span>]+ <span class="string">'\n'</span> +<span class="string">'Categorie: '</span>+data[<span class="string">'categorie'</span>]+<span class="string">'\n'</span>+<span class="string">'Price: '</span>+data[<span class="string">'price'</span>]+<span class="string">'\n'</span>+<span class="string">'Area: '</span>+data[<span class="string">'area'</span>] +<span class="string">'\n'</span> + <span class="string">'Review: '</span> + data[<span class="string">'review'</span>])</span><br><span class="line">            print(<span class="string">'=========================='</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line">get_detail_58(url)</span><br></pre></td></tr></table></figure></p>
<p>And we can check the result, after that, we will analysis this code.<br><figure class="highlight subunit"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Title: 苹果7 7p分期付款支持以旧换新</span><br><span class="line"><span class="keyword">Time:</span> 2017<span class="string">-03</span><span class="string">-28</span></span><br><span class="line">Categorie: 北京二手手机</span><br><span class="line">Price: 4199</span><br><span class="line">Area: 朝阳-朝外大街</span><br><span class="line">Review: 607</span><br><span class="line">===========================</span><br></pre></td></tr></table></figure></p>
<p>In this source code, we firstly built get_detail_58 function, it’s mainly to acquire each item’s information.<br>Title, price and time is very easy, we do not need show it.<br>On the categorie part, the result is <code>\r\n              北京二手手机</code>, so we can use <code>replace(&#39;\r\n&#39;,&#39;&#39;)</code> to replace the special symbols and then use <code>strip()</code> to remove extra space.<br>On the area part, if we scrapying it directly, the result is <code>海淀   -          中关村</code>,there are many space here, so we need to deal with the results.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">area_detail = <span class="string">''</span></span><br><span class="line">area = soup.select(<span class="string">'ul.suUl &gt; li:nth-of-type(3) &gt; div.su_con &gt; span.c_25d'</span>)[<span class="number">0</span>]</span><br><span class="line">area = list(area.stripped_strings)</span><br><span class="line">area = area_detail.join(area)</span><br></pre></td></tr></table></figure></p>
<p>On the view counts part, it need us to check the javascript file.<br> <img src="/images/58_7.png" class="[image1]"><br> so, look at our code, we define a function named <code>get_review(url)</code>,the url is the same as the item’s detail page’s url:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_review</span><span class="params">(url)</span>:</span></span><br><span class="line">    <span class="comment">#假如传入的URL是http://bj.58.com/shouji/29448470616899x.shtml,那么按‘\’分割后最后一个应该是29448470616899x.shtml，然后再用strip('x.html')，去掉x.html，这样就只剩下29448470616899，与js文件的infoid的值是相同的</span></span><br><span class="line">    part_link = url.split(<span class="string">'/'</span>)[<span class="number">-1</span>].strip(<span class="string">'x.shtml'</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment">#从header中看到这里的URL应该是http://jst1.58.com/counter?infoid=29448470616899,所以我们用format进行拼接。</span></span><br><span class="line">    url = <span class="string">'http://jst1.58.com/counter?infoid=&#123;&#125;'</span>.format(str(part_link))</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span>,</span><br><span class="line">        <span class="string">'Cookie'</span>:<span class="string">'id58=Ch8BCFjaxDmGEQfEAxATAg==; 58home=bj; als=0; commonTopbar_myfeet_tooltip=end; city=bj; myfeet_tooltip=end; bj58_id58s="WlB6dVpRaTAtTXZ1MTUxNg=="; sessionid=3f9c77fd-4820-45b2-9ec1-168efe3791b2; es_ab=1; 58tj_uuid=aff6d5b1-071f-4599-a863-3583cc4e2c14; new_uv=6; bj58_new_session=1; bj58_init_refer="http://bj.58.com/shouji/"; bj58_new_uv=4'</span>,</span><br><span class="line">        <span class="string">'Accept'</span>:<span class="string">'*/*'</span>,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>:<span class="string">'gzip, deflate, sdch'</span>,</span><br><span class="line">        <span class="string">'Accept-Language'</span>:<span class="string">'zh-CN,zh;q=0.8'</span>,</span><br><span class="line">        <span class="string">'Connection'</span>:<span class="string">'keep-alive'</span>,</span><br><span class="line">        <span class="string">'Host'</span>:<span class="string">'jst1.58.com'</span>,</span><br><span class="line">        <span class="string">'Referer'</span>:<span class="string">'http://bj.58.com/shouji/&#123;&#125;x.shtml'</span>.format(str(part_link))</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    resp = requests.get(url,headers=headers)</span><br><span class="line">    </span><br><span class="line">    <span class="comment">#从response中我们看到，浏览量的数值是返回代码的最后的数值，并且在一个=后面，所以我们可以这样进行取值</span></span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="keyword">return</span> resp.text.split(<span class="string">'='</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br></pre></td></tr></table></figure></p>
<p>Then we finished this part.</p>
<h2 id="Zhuanzhuan-Users-Link"><a href="#Zhuanzhuan-Users-Link" class="headerlink" title="Zhuanzhuan Users Link"></a>Zhuanzhuan Users Link</h2><p>This part we need scrapying the following information:<br><img src="/images/58_5.png" class="[image1]"><br>And from the source code, we don’t encounter any problem, so it is the scrapying code:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_zhuanzhuan_detail</span><span class="params">(url,data=None)</span>:</span></span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">        soup = BeautifulSoup(resp.text,<span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = &#123;</span><br><span class="line">                <span class="string">'title'</span>: soup.select(<span class="string">'div.info_lubotu.clearfix &gt; div.box_left_top &gt; h1'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'categorie'</span>: soup.select(<span class="string">'span.crb_i &gt; a'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'price'</span>: soup.select(<span class="string">'div.info_massege.left &gt; div.price_li &gt; span &gt; i'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'area'</span>: soup.select(<span class="string">'div.info_massege.left &gt; div.palce_li &gt; span &gt; i'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'sailer'</span>: soup.select(<span class="string">'div.personal_jieshao &gt; p.personal_name'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'review'</span>: soup.select(<span class="string">'div.box_left_top &gt; p &gt; span.look_time'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'label'</span>: list(soup.select(<span class="string">'div.info_massege.left &gt; div.biaoqian_li'</span>)[<span class="number">0</span>].stripped_strings)</span><br><span class="line">            &#125;</span><br><span class="line">            print(<span class="string">'Title: '</span>+data[<span class="string">'title'</span>]+<span class="string">'\n'</span>+<span class="string">'sailer: '</span>+ data[<span class="string">'sailer'</span>]+ <span class="string">'\n'</span> +<span class="string">'Categorie: '</span>+data[<span class="string">'categorie'</span>]+<span class="string">'\n'</span>+<span class="string">'Price: '</span>+data[<span class="string">'price'</span>]+<span class="string">'\n'</span>+<span class="string">'Area: '</span>+data[<span class="string">'area'</span>]+<span class="string">'\n'</span>+<span class="string">'Review: '</span>+data[<span class="string">'review'</span>]+<span class="string">'\n'</span>+<span class="string">'Label: '</span>+str(data[<span class="string">'label'</span>]))</span><br><span class="line">            print(<span class="string">'=========================='</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">            <span class="keyword">pass</span></span><br></pre></td></tr></table></figure></p>
<p>And the result is:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Title:</span> 苹果 iPhone7 Plus 金色 <span class="number">128</span>G 国行 苹果<span class="number">7</span> plus  国行版本  <span class="number">128</span>g的   金色的</span><br><span class="line"><span class="string">sailer:</span> 屠伍郤</span><br><span class="line"><span class="string">Categorie:</span> 北京二手市场</span><br><span class="line"><span class="string">Price:</span> <span class="number">4640</span></span><br><span class="line"><span class="string">Area:</span> 北京-昌平</span><br><span class="line"><span class="string">Review:</span> <span class="number">402</span>次浏览</span><br><span class="line"><span class="string">Label:</span> [<span class="string">'真实个人'</span>, <span class="string">'担保交易'</span>, <span class="string">'支持全国'</span>]</span><br><span class="line">==========================</span><br></pre></td></tr></table></figure></p>
<h2 id="Integration"><a href="#Integration" class="headerlink" title="Integration"></a>Integration</h2><p>Now we can integrate the whole item, the list and two detail pages:<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> requests</span><br><span class="line"></span><br><span class="line">url = <span class="string">'http://bj.58.com/shouji/'</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_list</span><span class="params">(url,data=None)</span>:</span></span><br><span class="line"></span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    soup = BeautifulSoup(resp.text,<span class="string">'lxml'</span>)</span><br><span class="line">    links = soup.select(<span class="string">'tbody &gt; tr &gt; td.t &gt; a.t'</span>)        </span><br><span class="line">    <span class="keyword">for</span> link <span class="keyword">in</span> links:</span><br><span class="line">        link = link.get(<span class="string">'href'</span>).split(<span class="string">'?'</span>)[<span class="number">0</span>]</span><br><span class="line">        <span class="keyword">if</span> link[<span class="number">0</span>:<span class="number">26</span>] != <span class="string">'http://jump.zhineng.58.com'</span>:</span><br><span class="line">            <span class="keyword">if</span> link[<span class="number">0</span>:<span class="number">17</span>] == <span class="string">'http://bj.58.com/'</span>:</span><br><span class="line">                get_detail_58(link)</span><br><span class="line">            <span class="keyword">elif</span> link[<span class="number">0</span>:<span class="number">17</span>] == <span class="string">'http://zhuanzhuan'</span>:</span><br><span class="line">                get_zhuanzhuan_detail(link)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                print(<span class="string">'Unknown Address'</span> + link)</span><br><span class="line">    </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_review</span><span class="params">(url)</span>:</span></span><br><span class="line">    part_link = url.split(<span class="string">'/'</span>)[<span class="number">-1</span>].strip(<span class="string">'x.shtml'</span>)</span><br><span class="line">    url = <span class="string">'http://jst1.58.com/counter?infoid=&#123;&#125;'</span>.format(str(part_link))</span><br><span class="line">    headers = &#123;</span><br><span class="line">        <span class="string">'User-Agent'</span>:<span class="string">'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_12_3) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/56.0.2924.87 Safari/537.36'</span>,</span><br><span class="line">        <span class="string">'Cookie'</span>:<span class="string">'id58=Ch8BCFjaxDmGEQfEAxATAg==; 58home=bj; als=0; commonTopbar_myfeet_tooltip=end; city=bj; myfeet_tooltip=end; bj58_id58s="WlB6dVpRaTAtTXZ1MTUxNg=="; sessionid=3f9c77fd-4820-45b2-9ec1-168efe3791b2; es_ab=1; 58tj_uuid=aff6d5b1-071f-4599-a863-3583cc4e2c14; new_uv=6; bj58_new_session=1; bj58_init_refer="http://bj.58.com/shouji/"; bj58_new_uv=4'</span>,</span><br><span class="line">        <span class="string">'Accept'</span>:<span class="string">'*/*'</span>,</span><br><span class="line">        <span class="string">'Accept-Encoding'</span>:<span class="string">'gzip, deflate, sdch'</span>,</span><br><span class="line">        <span class="string">'Accept-Language'</span>:<span class="string">'zh-CN,zh;q=0.8'</span>,</span><br><span class="line">        <span class="string">'Connection'</span>:<span class="string">'keep-alive'</span>,</span><br><span class="line">        <span class="string">'Host'</span>:<span class="string">'jst1.58.com'</span>,</span><br><span class="line">        <span class="string">'Referer'</span>:<span class="string">'http://bj.58.com/shouji/&#123;&#125;x.shtml'</span>.format(str(part_link))</span><br><span class="line"></span><br><span class="line">    &#125;</span><br><span class="line">    resp = requests.get(url,headers=headers)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">        <span class="keyword">return</span> resp.text.split(<span class="string">'='</span>)[<span class="number">-1</span>]</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span></span><br><span class="line"> </span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_detail_58</span><span class="params">(url,data=None)</span>:</span></span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">        soup = BeautifulSoup(resp.text,<span class="string">'lxml'</span>)</span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            area_detail = <span class="string">''</span></span><br><span class="line">            are a = soup.select(<span class="string">'ul.suUl &gt; li:nth-of-type(3) &gt; div.su_con &gt; span.c_25d'</span>)[<span class="number">0</span>]</span><br><span class="line">            area = list(area.stripped_strings)</span><br><span class="line">            area = area_detail.join(area)</span><br><span class="line"></span><br><span class="line">            data = &#123;</span><br><span class="line">                <span class="string">'title'</span>:soup.select(<span class="string">'div.per_ad_left &gt; div.col_sub.mainTitle &gt; h1'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'categorie'</span>:soup.select(<span class="string">'div.breadCrumb.f12 &gt; span:nth-of-type(3) &gt; a'</span>)[<span class="number">0</span>].text.replace(<span class="string">'\r\n'</span>,<span class="string">''</span>).strip(),</span><br><span class="line">                <span class="string">'price'</span>:soup.select(<span class="string">'div.su_con &gt; span.price.c_f50'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'area'</span>:area,</span><br><span class="line">                <span class="string">'time'</span>:soup.select(<span class="string">'ul.mtit_con_left.fl &gt; li.time'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'review'</span>:get_review(url)</span><br><span class="line">            &#125;</span><br><span class="line">            print(<span class="string">'Title: '</span>+data[<span class="string">'title'</span>]+<span class="string">'\n'</span>+<span class="string">'Time: '</span>+ data[<span class="string">'time'</span>]+ <span class="string">'\n'</span> +<span class="string">'Categorie: '</span>+data[<span class="string">'categorie'</span>]+<span class="string">'\n'</span>+<span class="string">'Price: '</span>+data[<span class="string">'price'</span>]+<span class="string">'\n'</span>+<span class="string">'Area: '</span>+data[<span class="string">'area'</span>] +<span class="string">'\n'</span> + <span class="string">'Review: '</span> + data[<span class="string">'review'</span>])</span><br><span class="line">            print(<span class="string">'=========================='</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_zhuanzhuan_detail</span><span class="params">(url,data=None)</span>:</span></span><br><span class="line">    resp = requests.get(url)</span><br><span class="line">    <span class="keyword">if</span> resp.status_code == <span class="number">200</span>:</span><br><span class="line">        soup = BeautifulSoup(resp.text,<span class="string">'lxml'</span>)</span><br><span class="line"></span><br><span class="line">        <span class="keyword">try</span>:</span><br><span class="line">            data = &#123;</span><br><span class="line">                <span class="string">'title'</span>: soup.select(<span class="string">'div.info_lubotu.clearfix &gt; div.box_left_top &gt; h1'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'categorie'</span>: soup.select(<span class="string">'span.crb_i &gt; a'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'price'</span>: soup.select(<span class="string">'div.info_massege.left &gt; div.price_li &gt; span &gt; i'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'area'</span>: soup.select(<span class="string">'div.info_massege.left &gt; div.palce_li &gt; span &gt; i'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'sailer'</span>: soup.select(<span class="string">'div.personal_jieshao &gt; p.personal_name'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'review'</span>: soup.select(<span class="string">'div.box_left_top &gt; p &gt; span.look_time'</span>)[<span class="number">0</span>].text,</span><br><span class="line">                <span class="string">'label'</span>: list(soup.select(<span class="string">'div.info_massege.left &gt; div.biaoqian_li'</span>)[<span class="number">0</span>].stripped_strings)</span><br><span class="line">            &#125;</span><br><span class="line">            print(<span class="string">'Title: '</span>+data[<span class="string">'title'</span>]+<span class="string">'\n'</span>+<span class="string">'sailer: '</span>+ data[<span class="string">'sailer'</span>]+ <span class="string">'\n'</span> +<span class="string">'Categorie: '</span>+data[<span class="string">'categorie'</span>]+<span class="string">'\n'</span>+<span class="string">'Price: '</span>+data[<span class="string">'price'</span>]+<span class="string">'\n'</span>+<span class="string">'Area: '</span>+data[<span class="string">'area'</span>]+<span class="string">'\n'</span>+<span class="string">'Review: '</span>+data[<span class="string">'review'</span>]+<span class="string">'\n'</span>+<span class="string">'Label: '</span>+str(data[<span class="string">'label'</span>]))</span><br><span class="line">            print(<span class="string">'=========================='</span>)</span><br><span class="line">        <span class="keyword">except</span> Exception <span class="keyword">as</span> e:</span><br><span class="line">            print(e)</span><br><span class="line">            <span class="keyword">pass</span></span><br><span class="line">get_list(url)</span><br></pre></td></tr></table></figure></p>
<p>And this is the final result:<br><figure class="highlight groovy"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">Title:</span> 授权实体店(分期）（置换）（高价回收）苹果、三星、华为、oppo、步步高、等各种机型</span><br><span class="line"><span class="string">Time:</span> <span class="number">2017</span><span class="number">-03</span><span class="number">-29</span></span><br><span class="line"><span class="string">Categorie:</span> 北京二手手机</span><br><span class="line"><span class="string">Price:</span> <span class="number">5000</span></span><br><span class="line"><span class="string">Area:</span> 海淀-中关村</span><br><span class="line"><span class="string">Review:</span> <span class="number">380</span></span><br><span class="line">==========================</span><br><span class="line"><span class="string">Title:</span> 正规实体店《火爆》《<span class="number">0</span>首付分期》,出售二手苹果,三星手机,支持以旧换新</span><br><span class="line"><span class="string">Time:</span> <span class="number">2017</span><span class="number">-03</span><span class="number">-21</span></span><br><span class="line"><span class="string">Categorie:</span> 北京二手手机</span><br><span class="line"><span class="string">Price:</span> <span class="number">1666</span></span><br><span class="line"><span class="string">Area:</span> 海淀-北京大学</span><br><span class="line"><span class="string">Review:</span> <span class="number">4472</span></span><br><span class="line">==========================</span><br><span class="line"><span class="string">Title:</span> 苹果<span class="number">7</span> <span class="number">7</span>p分期付款支持以旧换新</span><br><span class="line"><span class="string">Time:</span> <span class="number">2017</span><span class="number">-03</span><span class="number">-28</span></span><br><span class="line"><span class="string">Categorie:</span> 北京二手手机</span><br><span class="line"><span class="string">Price:</span> <span class="number">4199</span></span><br><span class="line"><span class="string">Area:</span> 朝阳-朝外大街</span><br><span class="line"><span class="string">Review:</span> <span class="number">624</span></span><br><span class="line">==========================</span><br><span class="line"><span class="string">Title:</span> 三星  <span class="number">16</span>G 转让三星 电信版<span class="number">3</span>G 全网通双卡手机</span><br><span class="line"><span class="string">sailer:</span> 京东 商城</span><br><span class="line"><span class="string">Categorie:</span> 北京二手市场</span><br><span class="line"><span class="string">Price:</span> <span class="number">200</span></span><br><span class="line"><span class="string">Area:</span> 北京-海淀</span><br><span class="line"><span class="string">Review:</span> <span class="number">30</span>次浏览</span><br><span class="line"><span class="string">Label:</span> [<span class="string">'真实个人'</span>, <span class="string">'担保交易'</span>, <span class="string">'支持全国'</span>]</span><br><span class="line">==========================</span><br><span class="line"><span class="string">Title:</span> 中兴  <span class="number">16</span>G 转让中兴BA910 全新手机</span><br><span class="line"><span class="string">sailer:</span> 青春hl</span><br><span class="line"><span class="string">Categorie:</span> 北京二手市场</span><br><span class="line"><span class="string">Price:</span> <span class="number">750</span></span><br><span class="line"><span class="string">Area:</span> 北京-丰台</span><br><span class="line"><span class="string">Review:</span> <span class="number">7</span>次浏览</span><br><span class="line"><span class="string">Label:</span> [<span class="string">'真实个人'</span>, <span class="string">'担保交易'</span>, <span class="string">'支持全国'</span>]</span><br><span class="line">==========================</span><br><span class="line"><span class="string">Title:</span> 三星 S7 edge <span class="number">32</span>G 三星s7edge  三星曲屏</span><br><span class="line"><span class="string">sailer:</span> 博衣城`</span><br><span class="line"><span class="string">Categorie:</span> 北京二手市场</span><br><span class="line"><span class="string">Price:</span> <span class="number">1900</span></span><br><span class="line"><span class="string">Area:</span> 北京-西城</span><br><span class="line"><span class="string">Review:</span> <span class="number">40</span>次浏览</span><br><span class="line"><span class="string">Label:</span> [<span class="string">'真实个人'</span>, <span class="string">'担保交易'</span>, <span class="string">'支持全国'</span>]</span><br><span class="line">==========================</span><br><span class="line"><span class="string">Title:</span> 苹果 iPhone6 金色 <span class="number">16</span>G 国行 iPhone <span class="number">6</span>金色官换机<span class="number">16</span>G，很新，一直作备用机用</span><br><span class="line"><span class="string">sailer:</span> 邓成<span class="number">82458829</span></span><br><span class="line"><span class="string">Categorie:</span> 北京二手市场</span><br><span class="line"><span class="string">Price:</span> <span class="number">1700</span></span><br><span class="line"><span class="string">Area:</span> 北京-海淀</span><br><span class="line"><span class="string">Review:</span> <span class="number">41</span>次浏览</span><br><span class="line"><span class="string">Label:</span> [<span class="string">'真实个人'</span>, <span class="string">'担保交易'</span>, <span class="string">'支持全国'</span>]</span><br><span class="line">==========================</span><br><span class="line"><span class="string">Title:</span> 苹果 iPhone6s Plus 银色 <span class="number">128</span>G 国行 女生转刚买几个月的苹果<span class="number">6</span>sp银白色三网通<span class="number">4</span>G</span><br><span class="line"><span class="string">sailer:</span> 默默的远观`</span><br><span class="line"><span class="string">Categorie:</span> 北京二手市场</span><br><span class="line"><span class="string">Price:</span> <span class="number">2579</span></span><br><span class="line"><span class="string">Area:</span> 北京-朝阳</span><br><span class="line"><span class="string">Review:</span> <span class="number">150</span>次浏览</span><br><span class="line"><span class="string">Label:</span> [<span class="string">'真实个人'</span>, <span class="string">'担保交易'</span>, <span class="string">'支持全国'</span>]</span><br><span class="line">==========================</span><br><span class="line">...</span><br></pre></td></tr></table></figure></p>

      
    </div>

    <div>
      
        

      
    </div>

    <div>
      
        

      
    </div>

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/Python/" rel="tag">#Python</a>
          
            <a href="/tags/BeautifulSoup/" rel="tag">#BeautifulSoup</a>
          
            <a href="/tags/requests/" rel="tag">#requests</a>
          
            <a href="/tags/javascript/" rel="tag">#javascript</a>
          
        </div>
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2017/03/31/Practice-2_-Download-Scarlett-Pictures-From-WeHeartit-With-Python/" rel="next" title="Practice2：Download Scarlet Witch's Picture From WeHeartit WebSite">
                <i class="fa fa-chevron-left"></i> Practice2：Download Scarlet Witch's Picture From WeHeartit WebSite
              </a>
            
          </div>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2017/04/22/Python-and-Encoding/" rel="prev" title="Python and Encoding">
                Python and Encoding <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          
  <div class="comments" id="comments">
    
      <div class="ds-thread" data-thread-key="2017/04/01/Practice-3_-Scrapying-58-Web-Site-List-And-Detail/"
           data-title="Practice3: Scrapying 58 WebSite List And Detail" data-url="http://clovel.cn/2017/04/01/Practice-3_-Scrapying-58-Web-Site-List-And-Detail/">
      </div>
    
  </div>


        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap" >
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview">
            Overview
          </li>
        </ul>
      

      <section class="site-overview sidebar-panel ">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
          <img class="site-author-image" itemprop="image"
               src="/images/logo.JPG"
               alt="Cheng Wang" />
          <p class="site-author-name" itemprop="name">Cheng Wang</p>
          <p class="site-description motion-element" itemprop="description">Start From Zero</p>
        </div>
        <nav class="site-state motion-element">
          <div class="site-state-item site-state-posts">
            <a href="/archives">
              <span class="site-state-item-count">14</span>
              <span class="site-state-item-name">posts</span>
            </a>
          </div>

          
            <div class="site-state-item site-state-categories">
              <a href="/categories">
                <span class="site-state-item-count">7</span>
                <span class="site-state-item-name">categories</span>
              </a>
            </div>
          

          
            <div class="site-state-item site-state-tags">
              <a href="/tags">
                <span class="site-state-item-count">29</span>
                <span class="site-state-item-name">tags</span>
              </a>
            </div>
          

        </nav>

        

        <div class="links-of-author motion-element">
          
            
              <span class="links-of-author-item">
                <a href="https://github.com/chengw1121" target="_blank" title="GitHub">
                  
                    <i class="fa fa-fw fa-github"></i>
                  
                  GitHub
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://twitter.com/wangcheng1121" target="_blank" title="Twitter">
                  
                    <i class="fa fa-fw fa-twitter"></i>
                  
                  Twitter
                </a>
              </span>
            
              <span class="links-of-author-item">
                <a href="https://www.facebook.com/cheng.wang.5055233" target="_blank" title="Facebook">
                  
                    <i class="fa fa-fw fa-facebook"></i>
                  
                  Facebook
                </a>
              </span>
            
          
        </div>

        
        
          <div class="cc-license motion-element" itemprop="license">
            <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" target="_blank">
              <img src="/images/cc-by-nc-sa.svg" alt="Creative Commons" />
            </a>
          </div>
        

        
        
      </section>

      
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">
            
              
            
            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Background"><span class="nav-number">1.</span> <span class="nav-text">Background</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scrapying-The-List"><span class="nav-number">2.</span> <span class="nav-text">Scrapying The List</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Scrapying-Detail"><span class="nav-number">3.</span> <span class="nav-text">Scrapying Detail</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#58-Users-Link"><span class="nav-number">3.1.</span> <span class="nav-text">58 Users Link</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Zhuanzhuan-Users-Link"><span class="nav-number">3.2.</span> <span class="nav-text">Zhuanzhuan Users Link</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Integration"><span class="nav-number">3.3.</span> <span class="nav-text">Integration</span></a></li></ol></li></ol></div>
            
          </div>
        </section>
      
      <!-- hack一个虚线出来 -->
      <section style="border-top:1px dotted #ccc;height:10px;"></section>
      <!-- weibo show -->
      <iframe width="100%" height="550" class="share_self"  frameborder="0" scrolling="no" src="http://widget.weibo.com/weiboshow/index.php?language=&width=0&height=120&fansRow=2&ptype=1&speed=0&skin=5&isTitle=1&noborder=1&isWeibo=0&isFans=0&uid=2177694017&verifier=24dcfc20&dpc=1"></iframe>
    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        

        <div class="copyright" >
  
  &copy;  2017 - 
  <span itemprop="copyrightYear">2018</span>
  <span class="with-love">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Cheng Wang</span>
</div>




        
      </div>
    </footer>

    <div class="back-to-top">
      <i class="fa fa-arrow-up"></i>
    </div>
  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  



  
  <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>

  
  <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>

  
  <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>

  
  <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.0"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.0"></script>



  

  
    
  

  <script type="text/javascript">
    var duoshuoQuery = {short_name:"clovec"};
    (function() {
      var ds = document.createElement('script');
      ds.type = 'text/javascript';ds.async = true;
      ds.id = 'duoshuo-script';
      ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//neveryu.github.io/js/src/embed.js';
      ds.charset = 'UTF-8';
      (document.getElementById('footer')
      || document.getElementsByTagName('body')[0]).appendChild(ds);
    })();
  </script>

  
    
    <script src="/lib/ua-parser-js/dist/ua-parser.min.js?v=0.7.9"></script>
    <script src="/js/src/hook-duoshuo.js"></script>
  






  
  

  

  

  

  <!-- 按需加载背景 -->
  <!-- 识别手机或电脑的js开始 -->  
  <script type="text/javascript">   
  (function(){  
    var res = GetRequest();  
    var par = res['index'];  
    if(par!='gfan'){  
      var ua=navigator.userAgent.toLowerCase();  
      var contains=function (a, b){  
          if(a.indexOf(b)!=-1){return true;}  
      };   
      if((contains(ua,"android") && contains(ua,"mobile"))||(contains(ua,"android") && contains(ua,"mozilla"))||(contains(ua,"android") && contains(ua,"opera"))||contains(ua,"ucweb7")||contains(ua,"iphone")){
        return false;
      } else {
        $.getScript("/js/src/particle.js");
      }
    }  
  })();  
  function GetRequest() {  
    var url = location.search;
    var theRequest = new Object();  
    if (url.indexOf("?") != -1) {  
      var str = url.substr(1);  
      strs = str.split("&");  
      for(var i = 0; i < strs.length; i ++) {  
        theRequest[strs[i].split("=")[0]]=unescape(strs[i].split("=")[1]);  
      }  
    }  
    return theRequest;  
  }  
  </script>  
  <!-- 识别手机或电脑的js结束 -->  

  <!-- 背景动画 -->
  <!-- <script type="text/javascript" src="/js/src/particle.js"></script> -->
  <!-- 页面点击小红心 -->
  <!-- <script type="text/javascript" src="/js/src/love.js"></script> -->

</body>
</html>
